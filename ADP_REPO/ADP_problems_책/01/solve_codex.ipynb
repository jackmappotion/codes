{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADP 01 – Full Solution (Codex)\n",
    "본 노트북은 prob.ipynb의 모든 문항(1~4번)을 재현성 있게 풀이합니다.\n",
    "- 데이터 경로: `../data`\n",
    "- 사용 라이브러리: pandas, numpy, scikit-learn, xgboost, statsmodels, seaborn, matplotlib\n",
    "- 재현성: `random_state=42` 고정, 데이터 전처리-모델링 파이프라인 일원화로 데이터 누수 방지"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. 공통 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from sklearn.model_selection import train_test_split, KFold, RepeatedKFold, cross_val_score, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, PolynomialFeatures\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "try:\n",
    "    from xgboost import XGBRegressor\n",
    "    _HAS_XGB = True\n",
    "except Exception:\n",
    "    _HAS_XGB = False\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "np.random.seed(42)\n",
    "RANDOM_STATE = 42\n",
    "sns.set(style='whitegrid', font='AppleGothic')  # 한글 폰트 환경에 맞게 조정하세요\n",
    "plt.rcParams['axes.unicode_minus'] = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 머신러닝 (50점)\n",
    "데이터: 학생 성적 데이터셋 (394행 소규모)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) 데이터 로드\n",
    "student_path = os.path.join('..', 'data', 'student_data.csv')\n",
    "df = pd.read_csv(student_path)\n",
    "target_col = 'grade'\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기본 정보\n",
    "print(df.shape)\n",
    "display(df.dtypes)\n",
    "display(df.describe(include='all').T.iloc[:20])\n",
    "\n",
    "# 결측치 비율\n",
    "na_rate = df.isna().mean().sort_values(ascending=False)\n",
    "display(na_rate.to_frame('na_rate'))\n",
    "\n",
    "# 수치형/범주형 구분\n",
    "num_cols = df.select_dtypes(include=np.number).columns.drop([target_col])\n",
    "cat_cols = df.select_dtypes(exclude=np.number).columns\n",
    "print('Numeric:', list(num_cols))\n",
    "print('Categorical:', list(cat_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 분포 확인\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12,4))\n",
    "sns.histplot(df[target_col], kde=True, ax=axes[0])\n",
    "axes[0].set_title('Target 분포 (grade)')\n",
    "\n",
    "sns.boxplot(x=df[target_col], ax=axes[1])\n",
    "axes[1].set_title('Target 박스플롯')\n",
    "plt.show()\n",
    "\n",
    "# 범주형 빈도\n",
    "for c in cat_cols:\n",
    "    plt.figure(figsize=(6,3))\n",
    "    sns.countplot(x=c, data=df)\n",
    "    plt.title(f'{c} 빈도')\n",
    "    plt.xticks(rotation=0)\n",
    "    plt.show()\n",
    "\n",
    "# 상관 (원-핫 후 상관계수로 개략 확인)\n",
    "corr_df = pd.get_dummies(df.drop(columns=[]), columns=cat_cols, drop_first=True)\n",
    "plt.figure(figsize=(10,8))\n",
    "sns.heatmap(corr_df.corr()[[target_col]].sort_values(by=target_col, ascending=False), annot=True, cmap='coolwarm')\n",
    "plt.title('Target과의 상관')\n",
    "plt.show()\n",
    "print('- 관찰: G1/G2 와 grade의 상관이 큼 → 선형모델에선 다중공선성 유의, 트리계열에선 상대적으로 덜 민감')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-2. 결측치 식별 및 대체 방법 제안"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(na_rate[na_rate>0])\n",
    "print(\"- 방법 A: 단순 대치(SimpleImputer) – 수치: 중앙값/ 평균, 범주: 최빈\")\n",
    "print(\"- 방법 B: KNN 대치(KNNImputer) – 수치형 주변 이웃 기반\")\n",
    "print(\"선택: 수치형은 KNNImputer, 범주형은 최빈 대치 후 원-핫 인코딩. 파이프라인 내부에서 학습셋 기준으로 fit하여 데이터 누수 방지.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-3. 범주형 인코딩 필요성 식별 및 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파이프라인용 전처리자 정의\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', KNNImputer(n_neighbors=5)),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse=False))\n",
    "])\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, list(num_cols)),\n",
    "        ('cat', categorical_transformer, list(cat_cols))\n",
    "    ]\n",
    ")\n",
    "print('범주형은 OneHot, 수치형은 KNN+스케일링 적용')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-4. 데이터 분할 방법 2가지 및 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# - 랜덤 분할\n",
    "# - (회귀의) 층화 유사 분할: y를 분위수로 binning하여 stratify 적용\n",
    "X = df.drop(columns=[target_col])\n",
    "y = df[target_col]\n",
    "\n",
    "# 회귀에서의 유사 층화: y를 구간화\n",
    "y_bins = pd.qcut(y, q=5, labels=False, duplicates='drop')\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=RANDOM_STATE, stratify=y_bins\n",
    ")\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-5. SVM/XGBoost/RandomForest 공통점과 적합성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('- 공통점: (1) 수치 입력 기반, (2) 회귀/분류 모두 가능, (3) 하이퍼파라미터 튜닝 중요, (4) 교차검증으로 일반화 성능 검증 필요')\n",
    "print('- 적합성: 입력 차원/표본수 적당, 비선형성 존재 가능 → SVM(RBF), 트리계열(RF/XGB) 모두 유효. 파이프라인으로 전처리 일원화가 핵심')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-6. 세 모델 학습/비교, 최종 선택 및 고찰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = KFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
    "\n",
    "def eval_model(name, model):\n",
    "    pipe = Pipeline([('pre', preprocessor), ('model', model)])\n",
    "    r2 = cross_val_score(pipe, X_train, y_train, scoring='r2', cv=cv)\n",
    "    rmse = -cross_val_score(pipe, X_train, y_train, scoring='neg_root_mean_squared_error', cv=cv)\n",
    "    return {\n",
    "        'name': name,\n",
    "        'r2_mean': r2.mean(), 'r2_std': r2.std(),\n",
    "        'rmse_mean': rmse.mean(), 'rmse_std': rmse.std()\n",
    "    }\n",
    "\n",
    "base_results = []\n",
    "base_results.append(eval_model('SVR', SVR(kernel='rbf')))\n",
    "base_results.append(eval_model('RandomForest', RandomForestRegressor(random_state=RANDOM_STATE)))\n",
    "if _HAS_XGB:\n",
    "    base_results.append(eval_model('XGB', XGBRegressor(random_state=RANDOM_STATE, n_estimators=300, learning_rate=0.1)))\n",
    "\n",
    "pd.DataFrame(base_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 간단 그리드서치로 상위 모델 튜닝 후 최종 평가\n",
    "searches = []\n",
    "\n",
    "svr_pipe = Pipeline([('pre', preprocessor), ('model', SVR())])\n",
    "svr_grid = {\n",
    "    'model__kernel': ['rbf'],\n",
    "    'model__C': [1, 5, 10, 20],\n",
    "    'model__gamma': ['scale', 0.1, 0.01],\n",
    "    'model__epsilon': [0.1, 0.2]\n",
    "}\n",
    "svr_search = GridSearchCV(svr_pipe, svr_grid, scoring='r2', cv=cv, n_jobs=-1)\n",
    "svr_search.fit(X_train, y_train)\n",
    "searches.append(('SVR', svr_search))\n",
    "\n",
    "rf_pipe = Pipeline([('pre', preprocessor), ('model', RandomForestRegressor(random_state=RANDOM_STATE))])\n",
    "rf_grid = {\n",
    "    'model__n_estimators': [300, 600],\n",
    "    'model__max_depth': [None, 6, 10],\n",
    "    'model__min_samples_leaf': [1, 2, 5]\n",
    "}\n",
    "rf_search = GridSearchCV(rf_pipe, rf_grid, scoring='r2', cv=cv, n_jobs=-1)\n",
    "rf_search.fit(X_train, y_train)\n",
    "searches.append(('RandomForest', rf_search))\n",
    "\n",
    "if _HAS_XGB:\n",
    "    xgb_pipe = Pipeline([('pre', preprocessor), ('model', XGBRegressor(random_state=RANDOM_STATE, n_estimators=400))])\n",
    "    xgb_grid = {\n",
    "        'model__max_depth': [3, 5, 7],\n",
    "        'model__learning_rate': [0.05, 0.1],\n",
    "        'model__subsample': [0.8, 1.0],\n",
    "        'model__colsample_bytree': [0.8, 1.0]\n",
    "    }\n",
    "    xgb_search = GridSearchCV(xgb_pipe, xgb_grid, scoring='r2', cv=cv, n_jobs=-1)\n",
    "    xgb_search.fit(X_train, y_train)\n",
    "    searches.append(('XGB', xgb_search))\n",
    "\n",
    "# 교차검증 성적 비교\n",
    "tune_rows = []\n",
    "for name, gs in searches:\n",
    "    tune_rows.append({'name': name, 'cv_best_score_r2': gs.best_score_, 'best_params': gs.best_params_})\n",
    "cv_summary = pd.DataFrame(tune_rows).sort_values('cv_best_score_r2', ascending=False)\n",
    "cv_summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트셋 성능 평가 (R2, RMSE) 및 최종 선택\n",
    "test_rows = []\n",
    "for name, gs in searches:\n",
    "    y_pred = gs.predict(X_test)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "    test_rows.append({'name': name, 'test_r2': r2, 'test_rmse': rmse})\n",
    "test_summary = pd.DataFrame(test_rows).sort_values('test_r2', ascending=False)\n",
    "test_summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 최종 모델은 테스트 R2 및 RMSE 기준 상위 모델을 채택합니다.\n",
    "- 한계와 보완: (1) G1/G2가 목표와 강상관 → 현업 목적에 맞춰 포함 여부 검토, (2) 이상치/편향 존재 시 로버스트 스케일러·튜닝, (3) 데이터 기간/분포 변화 모니터링 및 재학습 전략, (4) 특성공학과 SHAP 등 해석성 보강"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 통계분석 (50점) – 회귀 (총 29점)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 로드: 문제의 경로가 없을 수 있어 존재 시 로드, 없으면 대체 데이터 생성\n",
    "reg_path = os.path.join('..', 'data', 'prob_1_2_1.csv')\n",
    "if os.path.exists(reg_path):\n",
    "    df_reg = pd.read_csv(reg_path)\n",
    "    X_reg, y_reg = df_reg.iloc[:, :-1], df_reg.iloc[:, -1]\n",
    "    print('Loaded:', reg_path, X_reg.shape)\n",
    "else:\n",
    "    # 대체: 선형관계(기울기 3, 절편 5) + 잡음 데이터 생성 (독립변수 1개)\n",
    "    n=300\n",
    "    X_reg = pd.DataFrame({'x': np.linspace(-3, 3, n)})\n",
    "    y_reg = 3*X_reg['x'] + 5 + np.random.normal(0, 1.0, size=n)\n",
    "    print('Fallback synthetic data used:', X_reg.shape)\n",
    "\n",
    "X_tr, X_te, y_tr, y_te = train_test_split(X_reg, y_reg, test_size=0.2, random_state=RANDOM_STATE)\n",
    "X_tr.shape, X_te.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-1. 선형회귀: 결정계수와 RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_pipe = Pipeline([('scaler', StandardScaler(with_mean=True, with_std=True)), ('lr', LinearRegression())])\n",
    "lin_pipe.fit(X_tr, y_tr)\n",
    "pred = lin_pipe.predict(X_te)\n",
    "lin_r2 = r2_score(y_te, pred)\n",
    "lin_rmse = mean_squared_error(y_te, pred, squared=False)\n",
    "print({'R2': lin_r2, 'RMSE': lin_rmse})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-2. 릿지(Ridge): alpha=0.0~1.0 (0.1 간격) 탐색 후 성능 보고"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_pipe = Pipeline([('scaler', StandardScaler()), ('ridge', Ridge())])\n",
    "alphas = np.round(np.arange(0.0, 1.01, 0.1), 2)\n",
    "ridge_grid = {'ridge__alpha': alphas}\n",
    "ridge_search = GridSearchCV(ridge_pipe, ridge_grid, scoring='r2', cv=KFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE))\n",
    "ridge_search.fit(X_tr, y_tr)\n",
    "best_alpha_ridge = ridge_search.best_params_['ridge__alpha']\n",
    "ridge_pred = ridge_search.predict(X_te)\n",
    "ridge_r2 = r2_score(y_te, ridge_pred)\n",
    "ridge_rmse = mean_squared_error(y_te, ridge_pred, squared=False)\n",
    "print({'best_alpha': best_alpha_ridge, 'R2': ridge_r2, 'RMSE': ridge_rmse})\n",
    "pd.DataFrame({'alpha': alphas, 'cv_r2': ridge_search.cv_results_['mean_test_score']})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-3. 라쏘(Lasso): alpha=0.0~1.0 (0.1 간격) 탐색 후 성능 보고"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_pipe = Pipeline([('scaler', StandardScaler()), ('lasso', Lasso(max_iter=10000))])\n",
    "lasso_grid = {'lasso__alpha': alphas}\n",
    "lasso_search = GridSearchCV(lasso_pipe, lasso_grid, scoring='r2', cv=KFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE))\n",
    "lasso_search.fit(X_tr, y_tr)\n",
    "best_alpha_lasso = lasso_search.best_params_['lasso__alpha']\n",
    "lasso_pred = lasso_search.predict(X_te)\n",
    "lasso_r2 = r2_score(y_te, lasso_pred)\n",
    "lasso_rmse = mean_squared_error(y_te, lasso_pred, squared=False)\n",
    "print({'best_alpha': best_alpha_lasso, 'R2': lasso_r2, 'RMSE': lasso_rmse})\n",
    "pd.DataFrame({'alpha': alphas, 'cv_r2': lasso_search.cv_results_['mean_test_score']})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 다항 회귀 (12점) – 1~3차 계수 및 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 생성 (문항 제공 식과 동일)\n",
    "m = 100\n",
    "X = 6 * np.random.rand(m,1) - 3\n",
    "y = 3 * X**3 + X**2 + 2*X + 2 + np.random.randn(m,1)\n",
    "line = np.linspace(-3,3,200).reshape(-1,1)\n",
    "\n",
    "def fit_plot_deg(d):\n",
    "    pipe = Pipeline([('poly', PolynomialFeatures(degree=d, include_bias=False)), ('lr', LinearRegression())])\n",
    "    pipe.fit(X, y)\n",
    "    coefs = pipe.named_steps['lr'].coef_\n",
    "    y_hat = pipe.predict(line)\n",
    "    plt.figure(figsize=(5,4))\n",
    "    plt.scatter(X, y, s=15, alpha=0.6, label='data')\n",
    "    plt.plot(line, y_hat, color='crimson', label=f'deg={d}')\n",
    "    plt.title(f'Polynomial deg={d}')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    return coefs\n",
    "\n",
    "coef_d1 = fit_plot_deg(1)\n",
    "coef_d2 = fit_plot_deg(2)\n",
    "coef_d3 = fit_plot_deg(3)\n",
    "print('deg1 coef:', coef_d1)\n",
    "print('deg2 coef:', coef_d2)\n",
    "print('deg3 coef:', coef_d3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. ANOVA (9점) – 이원분산분석 및 통계표"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avocado_path = os.path.join('..', 'data', 'avocado.csv')\n",
    "df_avo = pd.read_csv(avocado_path)\n",
    "df_avo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이원분산분석: AveragePrice ~ region * type\n",
    "model = ols('AveragePrice ~ C(region) * C(type)', data=df_avo).fit()\n",
    "anova_tbl = sm.stats.anova_lm(model, typ=2)\n",
    "anova_tbl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('- 상호작용 PR(>F) < 0.05 이면 region:type 상호작용 존재')\n",
    "print('- 각 주효과 PR(>F) < 0.05 이면 해당 요인의 평균 차이 유의')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "general",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

